
import io, re, json, math
import numpy as np
import pandas as pd
import streamlit as st

EXAMPLE_SURVEY = """
1.您的性别
A.男
B.女
2.您的年级
A.大一
B.大二
C.大三
3.您的生源地
A.城镇
B.农村
4.您是否担任班干部
A.是
B.否
5.您是否独生子女
A.独生子女
B.非独生子女
6.我有拖延症
A非常不符合
B不符合
C不确定
D符合
E非常符合
7.如果我有需要做的事，我会先做，而不是去做一些其他的事情
A非常不符合
B不符合
C不确定
D符合
E非常符合
"""

# Optional: write .sav if pyreadstat is installed
try:
    import pyreadstat
    HAS_PYREADSTAT = True
except Exception:
    HAS_PYREADSTAT = False

st.set_page_config(page_title="问卷解析 + SPSS数据生成器", layout="wide")

def parse_survey_text(txt: str):
    lines = [l.strip() for l in txt.splitlines() if l.strip()]
    questions = []
    i = 0
    q_pat = re.compile(r'^(\d+)\s*[\.、]\s*(.+)$')
    opt_pat = re.compile(r'^([A-E])\s*[\.、]?\s*(.+)$')
    cur = None
    while i < len(lines):
        m = q_pat.match(lines[i])
        if m:
            if cur:
                questions.append(cur)
            cur = {"qid": int(m.group(1)), "stem": m.group(2).strip(), "options": {}}
            i += 1
            while i < len(lines) and not q_pat.match(lines[i]):
                om = opt_pat.match(lines[i])
                if om and cur is not None:
                    cur["options"][om.group(1)] = om.group(2).strip()
                i += 1
            continue
        i += 1
    if cur:
        questions.append(cur)
    for q in questions:
        opts = " ".join(q["options"].values())
        if any(k in opts for k in ["非常不符合","不符合","不确定","符合","非常符合"]):
            q["scale_type"] = "likert_fit"
        elif any(k in opts for k in ["同意","较同意","较不同意","不同意"]):
            q["scale_type"] = "likert_agree"
        else:
            q["scale_type"] = "categorical"
    return questions

def generate_latents(n, dim_names, corr_matrix=None, seed=42):
    rng = np.random.default_rng(seed)
    k = len(dim_names)
    if corr_matrix is None:
        Z = rng.standard_normal(size=(n, k))
    else:
        R = np.array(corr_matrix, dtype=float)
        R = (R + R.T) / 2.0
        w, V = np.linalg.eigh(R)
        w[w < 1e-8] = 1e-8
        Rpsd = (V * w) @ V.T
        L = np.linalg.cholesky(Rpsd)
        Z = rng.standard_normal(size=(n, k)) @ L.T
    return pd.DataFrame(Z, columns=dim_names)

def apply_group_effect(df_latents, group, target_dim, beta):
    df_latents[target_dim] = df_latents[target_dim] + beta * group
    return df_latents

def apply_mediation(df_latents, A, C, B, a=0.6, b=0.6, cprime=0.1, seed=42):
    rng = np.random.default_rng(seed)
    df_latents[C] = a * df_latents[A] + rng.standard_normal(len(df_latents)) * math.sqrt(max(1e-6, 1-a*a))
    # keep B reasonably scaled
    df_latents[B] = b * df_latents[C] + cprime * df_latents[A] + rng.standard_normal(len(df_latents)) * 0.7
    return df_latents

def latent_to_items(latent, n_items, mean=3.6, loading=0.8, noise=0.75, seed=42):
    rng = np.random.default_rng(seed)
    cont = mean + loading * latent[:,None] + rng.standard_normal(size=(len(latent), n_items)) * noise
    return np.clip(np.rint(cont), 1, 5).astype(int)

def make_spss_syntax_for_csv(csv_filename, df_cols, var_labels, value_labels):
    var_lines=[]
    for col in df_cols:
        if col=="ID":
            var_lines.append(f"{col} F8.0")
        else:
            var_lines.append(f"{col} F3.0")
    var_block=" \n  ".join(var_lines)

    vl = "\n".join([f"VARIABLE LABELS {k} '{v}'." for k,v in var_labels.items() if k in df_cols])

    blocks=[]
    for var, mapping in value_labels.items():
        if var not in df_cols:
            continue
        parts=[f"{k} '{v}'" for k,v in mapping.items()]
        blocks.append(f"VALUE LABELS {var}\n  " + "\n  ".join(parts) + ".")
    vlab="\n\n".join(blocks)

    return f"""* Auto-generated by Survey Synth WebApp.
GET DATA
  /TYPE=TXT
  /FILE='{csv_filename}'
  /ENCODING='UTF8'
  /DELCASE=LINE
  /DELIMITERS=","
  /QUALIFIER='"'
  /ARRANGEMENT=DELIMITED
  /FIRSTCASE=2
  /VARIABLES=
  {var_block}.
EXECUTE.

{vl}

{vlab}

EXECUTE.
"""

if "questions" not in st.session_state:
    st.session_state.questions = []
if "config" not in st.session_state:
    st.session_state.config = {}

st.title("问卷解析 + 维度/关系约束 + SPSS数据生成器（本地网页）")
tabs = st.tabs(["1) 导入/解析问卷", "2) 维度与计分配置", "3) 关系约束（差异/相关/中介）", "4) 生成与导出"])

with tabs[0]:
    st.subheader("粘贴问卷文本 → 自动识别题号/题干/选项")
    raw = st.text_area("问卷文本", value=st.session_state.get("raw_text",""), height=320)
    c1,c2 = st.columns([1,1])
    with c1:
        if st.button("解析问卷", type="primary", use_container_width=True):
            st.session_state.questions = parse_survey_text(raw)
            st.session_state.raw_text = raw
            st.success(f"已解析 {len(st.session_state.questions)} 道题。")
    with c2:
        if st.button("载入示例", use_container_width=True):
            st.session_state.raw_text = EXAMPLE_SURVEY
            st.session_state.questions = parse_survey_text(EXAMPLE_SURVEY)
            st.success(f"已载入示例并解析 {len(st.session_state.questions)} 道题。")

    if st.session_state.questions:
        dfq = pd.DataFrame([{
            "qid": q["qid"],
            "scale_type": q["scale_type"],
            "stem": q["stem"],
            "options": " | ".join([f"{k}:{v}" for k,v in q["options"].items()])
        } for q in st.session_state.questions]).sort_values("qid")
        st.dataframe(dfq, use_container_width=True)

with tabs[1]:
    st.subheader("配置：维度归属、反向题、样本量")
    qs = st.session_state.questions
    if not qs:
        st.info("先到第 1 页解析问卷。")
    else:
        if not st.session_state.config:
            st.session_state.config = {
                "N": 630,
                "seed": 42,
                "reverse_items": [],
                "dimensions": {
                    "A_dim": list(range(6, 15)),
                    "B_dim": list(range(15, 25)),
                    "C_dim": list(range(25, 35)),
                    "SchoolClimate": list(range(35, 59)),
                    "StudyHabits": list(range(59, 85)),
                },
            }
        cfg = st.session_state.config
        c1,c2 = st.columns([1,1])
        with c1:
            cfg["N"] = st.number_input("样本量 N", 30, 5000, int(cfg.get("N",630)), 10)
        with c2:
            cfg["seed"] = st.number_input("随机种子 seed", 0, 10000, int(cfg.get("seed",42)), 1)

        st.markdown("**维度归属（题号列表，可直接改）**")
        dim_df = pd.DataFrame([{"dimension":k, "qids":",".join(map(str,v))} for k,v in cfg.get("dimensions",{}).items()])
        edited = st.data_editor(dim_df, use_container_width=True, num_rows="dynamic")
        dims={}
        for _,row in edited.iterrows():
            name=str(row.get("dimension","")).strip()
            if not name: 
                continue
            qtxt=str(row.get("qids","")).strip()
            qids=[int(x.strip()) for x in qtxt.split(",") if x.strip().isdigit()]
            if qids:
                dims[name]=qids
        cfg["dimensions"]=dims

        rev_txt = st.text_input("反向题题号（逗号分隔）", value=",".join(map(str,cfg.get("reverse_items",[]))))
        cfg["reverse_items"]=[int(x.strip()) for x in rev_txt.split(",") if x.strip().isdigit()]

        cfg_json = st.text_area("config.json（可复制保存）", value=json.dumps(cfg, ensure_ascii=False, indent=2), height=220)
        if st.button("应用上方 JSON", type="primary"):
            st.session_state.config = json.loads(cfg_json)
            st.success("已应用。")
        st.download_button("下载 config.json", data=cfg_json.encode("utf-8"), file_name="config.json", mime="application/json")
        st.session_state.config = cfg

with tabs[2]:
    st.subheader("关系约束：性别差异、维度相关、中介模型")
    cfg = st.session_state.config
    qs = st.session_state.questions
    if not cfg or not qs:
        st.info("先完成第 1–2 页。")
    else:
        dims = list(cfg.get("dimensions",{}).keys())
        if len(dims) < 3:
            st.warning("维度数量不足（至少 3 个）。")
        else:
            st.markdown("### 性别差异（男=0 女=1）")
            target = st.selectbox("目标维度", dims, index=0)
            beta = st.slider("β（越大越容易显著）", 0.0, 1.5, 0.6, 0.05)
            cfg["gender_effect"]={"target_dim":target,"beta":float(beta)}

            st.markdown("### 维度相关")
            d1 = st.selectbox("维度A", dims, index=0, key="d1")
            d2 = st.selectbox("维度B", dims, index=1, key="d2")
            rho = st.slider("ρ", -0.9, 0.9, 0.4, 0.05)
            cfg["corr_constraint"]={"d1":d1,"d2":d2,"rho":float(rho)}

            st.markdown("### 中介：A→C→B")
            A = st.selectbox("A", dims, index=0, key="A")
            C = st.selectbox("C", dims, index=1, key="C")
            B = st.selectbox("B", dims, index=2, key="B")
            med_type = st.radio("中介类型", ["完全中介","部分中介"], horizontal=True)
            a = st.slider("a（A→C）", 0.0, 1.2, 0.6, 0.05)
            b = st.slider("b（C→B）", 0.0, 1.2, 0.6, 0.05)
            cprime = 0.0 if med_type=="完全中介" else st.slider("c'（A→B）", 0.0, 1.2, 0.2, 0.05)
            cfg["mediation"]={"A":A,"C":C,"B":B,"a":float(a),"b":float(b),"cprime":float(cprime)}
            st.session_state.config = cfg
            st.success("已保存关系约束。")

with tabs[3]:
    st.subheader("生成并导出（CSV / .sps / .sav）")
    cfg = st.session_state.config
    qs = st.session_state.questions
    if not cfg or not qs:
        st.info("先完成第 1–3 页。")
    else:
        dims_map = cfg.get("dimensions",{})
        dim_names = list(dims_map.keys())
        N = int(cfg.get("N",630))
        seed = int(cfg.get("seed",42))
        max_q = max([q["qid"] for q in qs])

        k = len(dim_names)
        R = np.eye(k)
        cc = cfg.get("corr_constraint")
        if cc and cc.get("d1") in dim_names and cc.get("d2") in dim_names:
            i = dim_names.index(cc["d1"]); j = dim_names.index(cc["d2"])
            R[i,j]=R[j,i]=float(cc.get("rho",0.0))

        if st.button("生成数据", type="primary"):
            rng = np.random.default_rng(seed)
            Z = generate_latents(N, dim_names, corr_matrix=R, seed=seed)

            gender01 = rng.integers(0,2,size=N)
            ge = cfg.get("gender_effect")
            if ge and ge.get("target_dim") in Z.columns:
                Z = apply_group_effect(Z, gender01, ge["target_dim"], float(ge.get("beta",0.0)))

            med = cfg.get("mediation")
            if med:
                A,C,B = med["A"], med["C"], med["B"]
                if A in Z.columns and C in Z.columns and B in Z.columns:
                    Z = apply_mediation(Z, A, C, B, a=float(med["a"]), b=float(med["b"]), cprime=float(med["cprime"]), seed=seed+7)

            out = pd.DataFrame({"ID": np.arange(1,N+1)})
            out["Q1"] = np.where(gender01==0, 1, 2)
            out["Q2"] = rng.choice([1,2,3], size=N, p=[0.35,0.40,0.25])
            out["Q3"] = rng.choice([1,2], size=N, p=[0.55,0.45])
            out["Q4"] = rng.choice([1,2], size=N, p=[0.28,0.72])
            out["Q5"] = rng.choice([1,2], size=N, p=[0.38,0.62])

            qid_to_dim={}
            for d,qids in dims_map.items():
                for qid in qids:
                    qid_to_dim[qid]=d
            rev=set(cfg.get("reverse_items",[]))

            for d in dim_names:
                qids=[qid for qid,dd in qid_to_dim.items() if dd==d and qid>=6]
                if not qids: 
                    continue
                qids=sorted(qids)
                disc = latent_to_items(Z[d].to_numpy(), len(qids), seed=seed+13+hash(d)%1000)
                for idx,qid in enumerate(qids):
                    x = disc[:,idx]
                    if qid in rev:
                        x = 6 - x
                    out[f"Q{qid}"]=x

            cols=["ID"]+[f"Q{i}" for i in range(1,max_q+1) if f"Q{i}" in out.columns]
            for d in dim_names:
                qcols=[f"Q{qid}" for qid in dims_map[d] if f"Q{qid}" in out.columns]
                if qcols:
                    out[f"{d}_mean"]=out[qcols].mean(axis=1)
                    cols.append(f"{d}_mean")
            out=out[cols]
            st.session_state.generated = out
            st.success(f"已生成 {N} 行 × {out.shape[1]} 列。")

        if "generated" in st.session_state:
            out = st.session_state.generated
            st.dataframe(out.head(50), use_container_width=True)

            var_labels={"ID":"Respondent ID","Q1":"您的性别","Q2":"您的年级","Q3":"您的生源地","Q4":"您是否担任班干部","Q5":"您是否独生子女"}
            for q in qs:
                var_labels[f"Q{q['qid']}"]=q["stem"][:240]
            for d in dim_names:
                if f"{d}_mean" in out.columns:
                    var_labels[f"{d}_mean"]=f"{d}（均分）"

            value_labels={
                "Q1":{1:"男",2:"女"},
                "Q2":{1:"大一",2:"大二",3:"大三"},
                "Q3":{1:"城镇",2:"农村"},
                "Q4":{1:"是",2:"否"},
                "Q5":{1:"独生子女",2:"非独生子女"},
            }
            for q in range(6, max_q+1):
                if f"Q{q}" in out.columns:
                    value_labels[f"Q{q}"]={1:"1",2:"2",3:"3",4:"4",5:"5"}

            csv_bytes = out.to_csv(index=False, encoding="utf-8-sig").encode("utf-8-sig")
            st.download_button("下载 CSV", data=csv_bytes, file_name="synthetic_data.csv", mime="text/csv")

            sps = make_spss_syntax_for_csv("synthetic_data.csv", out.columns.tolist(), var_labels, value_labels)
            st.download_button("下载 .sps（导入+标签）", data=sps.encode("utf-8"), file_name="import_and_label.sps", mime="text/plain")

            if HAS_PYREADSTAT:
                import tempfile, os
                with tempfile.NamedTemporaryFile(suffix=".sav", delete=False) as tf:
                    path=tf.name
                try:
                    pyreadstat.write_sav(out, path, column_labels=var_labels, variable_value_labels=value_labels)
                    with open(path,"rb") as f:
                        sav=f.read()
                    st.download_button("下载 .sav（含标签）", data=sav, file_name="synthetic_data.sav", mime="application/octet-stream")
                finally:
                    try: os.remove(path)
                    except: pass
            else:
                st.info("未检测到 pyreadstat：可用 CSV + .sps 导入 SPSS（等价）。")
